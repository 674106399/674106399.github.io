<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[带有返回值的多线程Python实例]]></title>
    <url>%2F2018%2F07%2F14%2Fthreads%2F</url>
    <content type="text"><![CDATA[计算密集型 vs. IO密集型我们根据任务对CPU的使用情况，可以把任务类型分为计算密集型和IO密集型，计算密集型任务需要大量占用计算资源，适合使用多进程执行，每个进程可以使用独立的CPU核心进行计算；IO密集型任务需要的计算量不大，但可能存在大量的IO、网络延迟等待，适合使用多线程执行。 有返回值的多线程实例Python初始的多线程对返回值的支持不是很好，我们可以通过类的继承来创建一个带有返回值的多线程类。 12345678910111213141516171819from threading import Thread class MyThread(Thread): def __init__(self, param1): Thread.__init__(self) self.param1 = param1 self.result = None def foo(self, param1): result = None # do something return result def run(self): self.result = self.foo(self.param1) def get_result(self): return self.result 然后我们就可以轻松地创建多线程： 123456789t_list = []for i in range(3): t = MyThread(i) t_list.append(t) t.start() for t in t_list: t.join() print(t.get_result()) 启动之后一定要t.join()将主程序阻塞，等待子进程运行结束，不然主线程比子线程跑的快，会拿不到结果。]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Thread</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Multiprocessing实用技能总结]]></title>
    <url>%2F2018%2F07%2F13%2Fmultiprocessing%2F</url>
    <content type="text"><![CDATA[为什么要使用Python多进程多线程并发具有内存共享、通信简单等优势，那么为什么我们还要选择多进程呢？下面我引用廖雪峰的Python教程中的一段说明： 因为Python的线程虽然是真正的线程，但解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。 GIL是Python解释器设计的历史遗留问题，通常我们用的解释器是官方实现的CPython，要真正利用多核，除非重写一个不带GIL的解释器。 所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。 不过，也不用过于担心，Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。 多进程的优势我们有很多的任务是相互独立运行的，也有很多任务实际上是可以通过拆分之后并行加速的。比如一个很大的list需要挨个遍历处理其中的元素，比如一组数据需要分别访问不同的方法处理得到不同的结果等等。 如果使用for loop来调用执行，实际上是一种串行的方式，必须要等待上一个任务结束才能执行下一个，中间会有大量的不必要的等待时间。 Pool我们使用进程池multiprocessing.Pool()来自动管理进程任务，首先要初始化进程池。 Pool方法接收一个参数MAX_TASKS，用于设置该进程池最多允许多少个子进程同时执行，若进程池中的子进程数大于MAX_TASKS，则剩余的子进程会进入等待，每当有子进程执行完毕，就会有新的子进程启动补充进去： 123from multiprocessing import PoolMAX_TASKS = 5pool = Pool(MAX_TASKS) 使用多进程可以加速计算的根本原因在于，可以利用多核CPU来分别执行不同的任务，因此最好先了解自己的CPU有多少个核心： 12# 该语句可以获取自己CPU的核心数NUM_CPUS = multiprocessing.cpu_count() 为避免多余的任务切换开销，一般MAX_TASKS不要大于NUM_CPUS。 然后我们需要定义一个function，该方法会被分配给每个新进程然后执行： 123def child_task(param1, param2): # do something return result 然后我们可以在主进程中调用apply_async方法来创建新进程并加入进程池中。 apply_async方法接受两个参数，第一个是要调用执行的方法，第二个是传递给该方法的参数： 1234567891011NUM_TASKS = 10results = []for i in range(NUM_TASKS): r = pool.apply_async(child_task, args=(param1, param2)) results.append(r)p.close() # 进程池停止接收新进程p.join() # 阻塞主进程，等待所有子进程结束for r in results: print(r.get()) 需要注意到上面的代码中，r.get()需要放到p.close()和p.join()执行进程池回收之后再使用。这是因为apply_async之后的语句是阻塞的，r.get()会等待上一条语句执行完毕才执行，因此获取返回值的过程最好放在进程池回收以后。]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>multiprocessing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用FPN和ROIalign来进行图像检索]]></title>
    <url>%2F2018%2F06%2F28%2F2018-6-28%2F</url>
    <content type="text"><![CDATA[上一版的模型出来以后测试发现一个问题，同一张图，低分辨率和高分辨率，检索结果完全不同。并且最气的是，这两张图相互查不到对方，模型输出的两个向量距离很远，这是不可接受的。 这个问题其实不难想到，深度模型每一层卷积都会对特征图进行压缩，在模型内部自然地形成一个金字塔形的结构（哪怕有padding操作，其实也只是在维持特征图尺寸，实际的信息依然被压缩，这是不可避免的）。就像一个逐渐抽象的过程中，势必要丢掉一些冗余信息，才能抓取到代表性的特征。 于是乎，当输入的图片本身分辨率很低，即含有的信息量很少时，这种深层压缩的结果会是毁灭性的。可以想象成从飞机上俯视地面上的一个人，你看到的或许仅仅是一个肉色的小色块了。 这个问题在目标检测中同样存在，之前流行的主流算法都是直接使用骨干网络的最后一层卷积图作为信息的载体，因此，当目标在图中的比例非常小时，往往很难被算法检测到。针对这个问题，Kaiming He大神提出了一个很厉害的通用结构FPN，仅仅是把它直接结合到Faster RCNN上，就让检测的召回率大大提升。 一般而言，不同阶段的卷积层输出含有不同层次的空间和语义信息，直接从模型的每一段提出来的卷积图是不能混合使用的。FPN通过top-down和横向连接，以及一个3*3的smooth layer解决了这个问题，使不同阶段的特征图语义统一成为现实。 对于低分辨率的图片，通过把深层卷积图上采样叠加到浅层卷积图上，可以在保留高层次语义信息的基础上，极大地保留空间信息。 k = floor(4 + sqrt(w * h) / 224) 通过这个公式，可以自动根据输入图片的尺寸来调整获取对应尺度的特征图。 这里有一个疑惑是，很明显在FPN结构中，P2会是该结构受益最大的层，因为它整合了所有阶段的卷积图信息，包含了最丰富的空间和语义信息。在Paper的消融实验里也证实，只使用P2卷积图就能得到非常好的效果。那么为什么还要使用不同阶段的特征图？或者说，何不直接对所有尺度的图片使用P2特征图？ 我的猜测是，也许对于高分辨率图片，其包含的空间信息过于庞大，即使通过深层模型依然可以有所保留，因而不需要再从浅层卷积图获取，这种特征图叠加融合的手段，主要目的还是在改善低分辨率的性能，是一种补偿手段，在高分辨率图上反而会因信息过多而再次带来语义的不统一，这是一种空间与语义的权衡折中。 从直觉上，通过在图片上建立FPN，再选择合适的尺度特征，就可以用来进行图像检索。相较于目标检测中有RPN提供ROI，在图像检索中只能以整张图作为输入，与ROI类似的，图片的比例也往往不是标准的1:1，提取得到的特征图也是如此，直接插值放缩是不可行的，会破坏原有的空间结构，因此还需要引入ROI池化来使得特征维度统一。根据Mask RCNN的研究，ROI池化存在各种各样的不足之处，ROIalign是一个更好的策略。 图像检索不同于目标检测的另一点是，ROI的边界往往是紧贴检测对象的，换言之，目标会充满整个ROI；而图片并非如此，往往还会存在大量的留白区域，因此直接对全图进行ROIalign同样会导致得到的特征的不一致，这里我才用了以下策略来对要输入模型的图片进行预处理： 1234567# 伪代码# 获取长边pad = img.width if img.width &gt; img.height else img.height# 用长边对图片进行扩充Padding(img)# 从图片中心截取pad*pad的区域CenterCrop(img, pad) 如此一来，我们就得到了将短边延拓到长边尺寸的图片。我们在这个图片的基础上进行FPN和ROIalign得到最终的特征向量。]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>FPN</tag>
        <tag>ROIalign</tag>
        <tag>Image Retrieval</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随笔：人类语言与神经网络类比]]></title>
    <url>%2F2018%2F05%2F31%2F2018-5-31%2F</url>
    <content type="text"><![CDATA[在神经网络构筑的维度空间中不断变换的向量，其实很像一种语言，训练神经网络，如同在创造一门新的符号语言。 我觉得这是一个很有意思的类比，人类的语言和特征向量之间，存在着很多有意思的相似之处。 当一张图片通过神经网络后，变为了一条某维度里的向量，这个过程就如同人看见这张图片后，可以描述图片内容为：一只很像熊猫的动物懒洋洋地趴在翠绿色的竹林正中间的灰色的石头上。这句描述的话就可以看成一个向量。 向量的维度是可以变换的，就如同语言描述可以改变，同样的一张图片，或许我们也可以描述为：一只熊猫，或者一只熊猫趴在石头上。 我们的分类模型其实就是把输出的向量维度数与分类个数联系在了一起，在“人，狗，熊猫”这个三分类的问题下，毫无疑问那张图片会在“熊猫”上得分最高。 卷积神经网络之所以更加成功，原因就在于它更关注局部特征，如果要类比的话，我觉得它就像一种针对细节进行详细描述的语言修辞，而全连接层更像在归纳总结一些关键词或者概述性的语言：图片通过卷积网络后我们得到了一串非常冗长的、细碎的细节描写，然后通过全连接层变为一系列关键词。 假如我们在最后的全连接层前面新加入了一层，问题就变得很有意思了，假如还是“人，狗，熊猫”的三分类问题，我们在前面加入了一层100个单元的隐藏层，这个过程就好像是先把卷积层的描述归纳为100个关键词，且这100个词的不同权重组合能够最终归纳为“人，狗，熊猫”。]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>卷积层</tag>
        <tag>全连接层</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[随笔：飞机上1]]></title>
    <url>%2F2018%2F05%2F28%2F2018-5-28%2F</url>
    <content type="text"><![CDATA[2018.5.28 21:00 成都-&gt;北京 在生活中你我应该都有过这样的经历：自己的某种想法、某种情感、某种感受，找不到任何词句来形容，不论怎么组织语言，表达出来的东西似乎都离自己内心的那个点差了些什么。 你我应该也都有过这种体验：某时某刻，突然听到某个人说的一句话，某首歌的一节词，某篇文章的一些句子，突然直戳内心，道尽了你一直以来难以言表的某些东西，使你感到从内到外的深切共鸣。 夏目漱石曾有一个经典的比喻，他形容日语是高情境的语言，当日本人希望表达“我爱你”时，用“月色真美”将会更加恰当。木心说“文字的简练来源于内心的真诚，我十二万分的爱你，就不如说，我爱你”。 我们的思想、情感、感受、思维，应该是一种很高维度的东西，而相比之下，我们的语言是低维的。所以才会出现那么多的词不达意、难以言说。]]></content>
      <categories>
        <category>Notes</category>
      </categories>
      <tags>
        <tag>思维 语言 夏目漱石 木心 维度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无题]]></title>
    <url>%2F2018%2F05%2F09%2F%E6%97%A0%E9%A2%98%2F</url>
    <content type="text"><![CDATA[看着秋日四五点的太阳 总想到行将沉没的爱情 虽然还留有光辉的外表在强装 但我们都明晰地感觉到那里面已经冷了 或许必须承认的是其中还有温度吧 但我们都诚实地添了衣服 为迎接不远到来的寒夜 这看上去像是一种要自欺的态度 现实又冷厉得无可辩驳 此时沐浴在余晖下面 街上的行人是最线条分明的 多情者纵情开怀及时行乐 痴情者惘然自立冰冷不觉 无情者故自前行目不斜分 一时街道上疏影横斜泾渭明 前望后顾恍如一般景色 竟像是身立明镜之前 然陷身其内又不知左右何方是人何处是影 所以我讷讷然站在那里 唯恐撞上冰冷坚硬的镜面 身觉冰冷入袭却举步不得 落在旁人眼里 大概一如我所见的街上众人吧]]></content>
      <categories>
        <category>Emotion</category>
      </categories>
      <tags>
        <tag>脉络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文笔记：Faster R-CNN Features for Instance Search]]></title>
    <url>%2F2018%2F05%2F07%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9AFaster%20R-CNN%20Features%20for%20Instance%20Search%2F</url>
    <content type="text"><![CDATA[[CVPR 2016] Faster R-CNN Features for Instance SearchPaper: Link Abstract 研究基于CNN的目标检测网络得到的feature是否有利于image retrieval 研究对目标检测网络进行fine-tune后检索效果是否有所提升 实验数据集： Oxford Building 5K Paris Buildings 6K TRECVid Instance Search 2013 What they do 通过一次前向传播从CNN中提取出图像的全局和局部特征 利用从RPN中学到的位置信息设计空间重排方案 分析了对目标检测CNN进行fine-tune对检索的影响 Conclusion 利用目标检测的CNN特征可以用于图像检索 使用检索的图像对CNN进行微调，可以较大提升检索效果 IntroductionBackground 利用预训练的CNNs提取现成的特征，在图像检索通用数据集上获得了不错的效果 实例检索系统 = 快速筛选（对数据库进行重排） + 高级检索（一些高计算量的阶段）。 常见的重排方式有几何验证和空间分析 空间分析重排是指，使用不同尺寸的滑动窗口滑过图像，获得图像内部不同局部区域的特征表达，将这些局部特征与查询实例进行比对。 Related WorkCNNs for Instance Search 早期研究中利用全连接层的特征进行图像检索 将从不同图像sub-patches提取的全连接层特征进行结合，得到更好的结果 研究发现图像检索领域使用卷积层特征进行，比全连接层特征结果更好 Object Detection CNNs 早期使用滑动窗口方法 随后R-CNN采用Selective Search 现在使用端到端的方法 MethodologyCNN-based Representations 作者将查询实例定义为找到包含查询目标的边界框 提出两种池化方案： Image-wise pooling of activations(IPA):忽略操作目标建议的所有层，只从最后一个卷积层提取特征，对所有滤波器的输出进行求和 Region-wise pooling of activations(RPA)：利用区域池化层提取RPN得到的目标建议的特征。对于每个建议窗口，都可以利用其中RoI池化层的输出来生成表达。 求和池化需要进行L2标准化、白化、L2标准化，而最大池化仅仅进行一次L2标准化 Fine-tuning Faster R-CNN 作者提出了两种微调方案： 只更新分类这一分支的全连接层的权重 前两个卷积层之后的所有层都更新 Image Retrieval 作者提出检索由三步构成： 快速筛选 空间重排 扩展查询 快速筛选是利用IPA，即图像的全局表达进行一次过滤，只保留前N个结果 空间重排由两种方法： CA-SR：假设类别不可知，将查询实例经过网络得到的所有RPA，与快速筛选后剩下的每幅图的RPA进行比较 CS-SR：使用微调后的网络，可以用每个RPN预测的分类得分作为查询对象的相似分数 扩展查询策略为取重排后的前M个结果的特征向量，对他们进行求和平均，用平均后得到的结果重新进行一次查询 Notes图像检索实际上是把图片转为向量在高维空间中位置的比较，两个向量越近，距离越短，则说明越相似。直接使用从整张图片得到的特征向量进行比对的图片检索系统效果有很大的优化空间，因为图片中与检索目标无关的信息越多，就会加大向量在其他维度的权重，进而使得向量在空间中的位置发生偏移，与希望得到的结果的距离变大，这种现象随着查询目标在原图中所占比例的大小越小、显著性越低、对比越不强烈，检索偏差也会越大。 举一个比较简单而极端的例子：我们可以想象有一个10维的空间，在这个空间中，只有第1，2，3维的方向上代表了我们所查询的对象的表达（实际上可能每个维度上都有不同的权重，在这里我们极端地假设其他维度上权重为0）。通过CNN得到的特征向量，实际上是由图片内的内容共同组成的，与我们所查询的对象无关的内容也掺杂其中，这些无关内容在10维空间中标示为其他维度上的不同权重。 因此，图片全局的表达可以用作第一步的快速筛选，然后再使用局部表达精确检索。]]></content>
      <categories>
        <category>Technology</category>
      </categories>
      <tags>
        <tag>Image Retrieval</tag>
        <tag>CV</tag>
        <tag>Deep Learning</tag>
      </tags>
  </entry>
</search>
