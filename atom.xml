<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>镜子的掌纹</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-05-31T19:02:07.233Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Tau Jiang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>随笔：人类语言与神经网络类比</title>
    <link href="http://yoursite.com/2018/05/31/2018-5-31/"/>
    <id>http://yoursite.com/2018/05/31/2018-5-31/</id>
    <published>2018-05-31T09:29:06.000Z</published>
    <updated>2018-05-31T19:02:07.233Z</updated>
    
    <content type="html"><![CDATA[<p>在神经网络构筑的维度空间中不断变换的向量，其实很像一种语言，训练神经网络，如同在创造一门新的符号语言。</p><p>我觉得这是一个很有意思的类比，人类的语言和特征向量之间，存在着很多有意思的相似之处。</p><p>当一张图片通过神经网络后，变为了一条某维度里的向量，这个过程就如同人看见这张图片后，可以描述图片内容为：一只很像熊猫的动物懒洋洋地趴在翠绿色的竹林正中间的灰色的石头上。这句描述的话就可以看成一个向量。</p><p>向量的维度是可以变换的，就如同语言描述可以改变，同样的一张图片，或许我们也可以描述为：一只熊猫，或者一只熊猫趴在石头上。</p><p>我们的分类模型其实就是把输出的向量维度数与分类个数联系在了一起，在“人，狗，熊猫”这个三分类的问题下，毫无疑问那张图片会在“熊猫”上得分最高。</p><p>卷积神经网络之所以更加成功，原因就在于它更关注局部特征，如果要类比的话，我觉得它就像一种针对细节进行详细描述的语言修辞，而全连接层更像在归纳总结一些关键词或者概述性的语言：图片通过卷积网络后我们得到了一串非常冗长的、细碎的细节描写，然后通过全连接层变为一系列关键词。</p><p>假如我们在最后的全连接层前面新加入了一层，问题就变得很有意思了，假如还是“人，狗，熊猫”的三分类问题，我们在前面加入了一层100个单元的隐藏层，这个过程就好像是先把卷积层的描述归纳为100个关键词，且这100个词的不同权重组合能够最终归纳为“人，狗，熊猫”。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在神经网络构筑的维度空间中不断变换的向量，其实很像一种语言，训练神经网络，如同在创造一门新的符号语言。&lt;/p&gt;
&lt;p&gt;我觉得这是一个很有意思的类比，人类的语言和特征向量之间，存在着很多有意思的相似之处。&lt;/p&gt;
&lt;p&gt;当一张图片通过神经网络后，变为了一条某维度里的向量，这个
      
    
    </summary>
    
      <category term="Notes" scheme="http://yoursite.com/categories/Notes/"/>
    
    
      <category term="卷积层" scheme="http://yoursite.com/tags/%E5%8D%B7%E7%A7%AF%E5%B1%82/"/>
    
      <category term="全连接层" scheme="http://yoursite.com/tags/%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82/"/>
    
      <category term="神经网络" scheme="http://yoursite.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>随笔：飞机上1</title>
    <link href="http://yoursite.com/2018/05/28/2018-5-28/"/>
    <id>http://yoursite.com/2018/05/28/2018-5-28/</id>
    <published>2018-05-28T13:44:12.000Z</published>
    <updated>2018-05-31T17:41:49.953Z</updated>
    
    <content type="html"><![CDATA[<p>2018.5.28 21:00 成都-&gt;北京</p><p>在生活中你我应该都有过这样的经历：自己的某种想法、某种情感、某种感受，找不到任何词句来形容，不论怎么组织语言，表达出来的东西似乎都离自己内心的那个点差了些什么。</p><p>你我应该也都有过这种体验：某时某刻，突然听到某个人说的一句话，某首歌的一节词，某篇文章的一些句子，突然直戳内心，道尽了你一直以来难以言表的某些东西，使你感到从内到外的深切共鸣。</p><p>夏目漱石曾有一个经典的比喻，他形容日语是高情境的语言，当日本人希望表达“我爱你”时，用“月色真美”将会更加恰当。木心说“文字的简练来源于内心的真诚，我十二万分的爱你，就不如说，我爱你”。</p><p>我们的思想、情感、感受、思维，应该是一种很高维度的东西，而相比之下，我们的语言是低维的。所以才会出现那么多的词不达意、难以言说。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;2018.5.28 21:00 成都-&amp;gt;北京&lt;/p&gt;
&lt;p&gt;在生活中你我应该都有过这样的经历：自己的某种想法、某种情感、某种感受，找不到任何词句来形容，不论怎么组织语言，表达出来的东西似乎都离自己内心的那个点差了些什么。&lt;/p&gt;
&lt;p&gt;你我应该也都有过这种体验：某时某
      
    
    </summary>
    
      <category term="Notes" scheme="http://yoursite.com/categories/Notes/"/>
    
    
      <category term="思维 语言 夏目漱石 木心 维度" scheme="http://yoursite.com/tags/%E6%80%9D%E7%BB%B4-%E8%AF%AD%E8%A8%80-%E5%A4%8F%E7%9B%AE%E6%BC%B1%E7%9F%B3-%E6%9C%A8%E5%BF%83-%E7%BB%B4%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>无题</title>
    <link href="http://yoursite.com/2018/05/09/%E6%97%A0%E9%A2%98/"/>
    <id>http://yoursite.com/2018/05/09/无题/</id>
    <published>2018-05-09T08:40:56.000Z</published>
    <updated>2018-05-09T08:54:37.845Z</updated>
    
    <content type="html"><![CDATA[<p>看着秋日四五点的太阳</p><p>总想到行将沉没的爱情</p><p>虽然还留有光辉的外表在强装</p><p>但我们都明晰地感觉到那里面已经冷了</p><p>或许必须承认的是其中还有温度吧</p><p>但我们都诚实地添了衣服</p><p>为迎接不远到来的寒夜</p><p>这看上去像是一种要自欺的态度</p><p>现实又冷厉得无可辩驳</p><p>此时沐浴在余晖下面</p><p>街上的行人是最线条分明的</p><p>多情者纵情开怀及时行乐</p><p>痴情者惘然自立冰冷不觉</p><p>无情者故自前行目不斜分</p><p>一时街道上疏影横斜泾渭明</p><p>前望后顾恍如一般景色</p><p>竟像是身立明镜之前</p><p>然陷身其内又不知左右何方是人何处是影</p><p>所以我讷讷然站在那里</p><p>唯恐撞上冰冷坚硬的镜面</p><p>身觉冰冷入袭却举步不得</p><p>落在旁人眼里</p><p>大概一如我所见的街上众人吧</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;看着秋日四五点的太阳&lt;/p&gt;
&lt;p&gt;总想到行将沉没的爱情&lt;/p&gt;
&lt;p&gt;虽然还留有光辉的外表在强装&lt;/p&gt;
&lt;p&gt;但我们都明晰地感觉到那里面已经冷了&lt;/p&gt;
&lt;p&gt;或许必须承认的是其中还有温度吧&lt;/p&gt;
&lt;p&gt;但我们都诚实地添了衣服&lt;/p&gt;
&lt;p&gt;为迎接不远到来的寒夜&lt;/p
      
    
    </summary>
    
      <category term="Emotion" scheme="http://yoursite.com/categories/Emotion/"/>
    
    
      <category term="脉络" scheme="http://yoursite.com/tags/%E8%84%89%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>论文笔记：Faster R-CNN Features for Instance Search</title>
    <link href="http://yoursite.com/2018/05/07/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%EF%BC%9AFaster%20R-CNN%20Features%20for%20Instance%20Search/"/>
    <id>http://yoursite.com/2018/05/07/论文阅读笔记：Faster R-CNN Features for Instance Search/</id>
    <published>2018-05-06T16:36:53.000Z</published>
    <updated>2018-05-09T09:25:55.192Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CVPR-2016-Faster-R-CNN-Features-for-Instance-Search"><a href="#CVPR-2016-Faster-R-CNN-Features-for-Instance-Search" class="headerlink" title="[CVPR 2016] Faster R-CNN Features for Instance Search"></a>[CVPR 2016] Faster R-CNN Features for Instance Search</h1><p>Paper: <a href="https://arxiv.org/abs/1604.08893" target="_blank" rel="noopener">Link</a></p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul><li>研究基于CNN的目标检测网络得到的feature是否有利于image retrieval</li><li>研究对目标检测网络进行fine-tune后检索效果是否有所提升</li><li>实验数据集：<ul><li>Oxford Building 5K</li><li>Paris Buildings 6K</li><li>TRECVid Instance Search 2013</li></ul></li></ul><h3 id="What-they-do"><a href="#What-they-do" class="headerlink" title="What they do"></a>What they do</h3><ul><li>通过一次前向传播从CNN中提取出图像的全局和局部特征</li><li>利用从RPN中学到的位置信息设计空间重排方案</li><li>分析了对目标检测CNN进行fine-tune对检索的影响</li></ul><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><ul><li>利用目标检测的CNN特征可以用于图像检索</li><li>使用检索的图像对CNN进行微调，可以较大提升检索效果</li></ul><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><ol><li>利用预训练的CNNs提取现成的特征，在图像检索通用数据集上获得了不错的效果</li><li>实例检索系统 = 快速筛选（对数据库进行重排） + 高级检索（一些高计算量的阶段）。</li><li>常见的重排方式有<strong>几何验证</strong>和<strong>空间分析</strong></li><li>空间分析重排是指，使用不同尺寸的滑动窗口滑过图像，获得图像内部不同局部区域的特征表达，将这些局部特征与查询实例进行比对。</li></ol><h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><h4 id="CNNs-for-Instance-Search"><a href="#CNNs-for-Instance-Search" class="headerlink" title="CNNs for Instance Search"></a>CNNs for Instance Search</h4><ul><li>早期研究中利用全连接层的特征进行图像检索</li><li>将从不同图像sub-patches提取的全连接层特征进行结合，得到更好的结果</li><li>研究发现图像检索领域使用卷积层特征进行，比全连接层特征结果更好</li></ul><h4 id="Object-Detection-CNNs"><a href="#Object-Detection-CNNs" class="headerlink" title="Object Detection CNNs"></a>Object Detection CNNs</h4><ul><li>早期使用滑动窗口方法</li><li>随后R-CNN采用Selective Search</li><li>现在使用端到端的方法</li></ul><h2 id="Methodology"><a href="#Methodology" class="headerlink" title="Methodology"></a>Methodology</h2><h3 id="CNN-based-Representations"><a href="#CNN-based-Representations" class="headerlink" title="CNN-based Representations"></a>CNN-based Representations</h3><ul><li>作者将查询实例定义为找到<strong>包含查询目标的边界框</strong></li><li>提出两种池化方案：<ul><li><strong>Image-wise pooling of activations(IPA)</strong>:忽略操作目标建议的所有层，只从最后一个卷积层提取特征，对所有滤波器的输出进行求和</li><li><strong>Region-wise pooling of activations(RPA)</strong>：利用区域池化层提取RPN得到的目标建议的特征。对于每个建议窗口，都可以利用其中RoI池化层的输出来生成表达。</li></ul></li><li>求和池化需要进行L2标准化、白化、L2标准化，而最大池化仅仅进行一次L2标准化</li></ul><h3 id="Fine-tuning-Faster-R-CNN"><a href="#Fine-tuning-Faster-R-CNN" class="headerlink" title="Fine-tuning Faster R-CNN"></a>Fine-tuning Faster R-CNN</h3><ul><li>作者提出了两种微调方案：<ol><li>只更新分类这一分支的全连接层的权重</li><li>前两个卷积层之后的所有层都更新</li></ol></li></ul><h3 id="Image-Retrieval"><a href="#Image-Retrieval" class="headerlink" title="Image Retrieval"></a>Image Retrieval</h3><ul><li>作者提出检索由三步构成：<ol><li>快速筛选</li><li>空间重排</li><li>扩展查询</li></ol></li><li>快速筛选是利用IPA，即图像的全局表达进行一次过滤，只保留前N个结果</li><li>空间重排由两种方法：<ol><li>CA-SR：假设类别不可知，将查询实例经过网络得到的所有RPA，与快速筛选后剩下的每幅图的RPA进行比较</li><li>CS-SR：使用微调后的网络，可以用每个RPN预测的分类得分作为查询对象的相似分数</li></ol></li><li>扩展查询策略为取重排后的前M个结果的特征向量，对他们进行求和平均，用平均后得到的结果重新进行一次查询</li></ul><h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><p>图像检索实际上是把图片转为向量在高维空间中位置的比较，两个向量越近，距离越短，则说明越相似。直接使用从整张图片得到的特征向量进行比对的图片检索系统效果有很大的优化空间，因为图片中与检索目标无关的信息越多，就会加大向量在其他维度的权重，进而使得向量在空间中的位置发生偏移，与希望得到的结果的距离变大，这种现象随着查询目标在原图中所占比例的大小越小、显著性越低、对比越不强烈，检索偏差也会越大。</p><p>举一个比较简单而极端的例子：我们可以想象有一个10维的空间，在这个空间中，只有第1，2，3维的方向上代表了我们所查询的对象的表达（实际上可能每个维度上都有不同的权重，在这里我们极端地假设其他维度上权重为0）。通过CNN得到的特征向量，实际上是由图片内的内容共同组成的，与我们所查询的对象无关的内容也掺杂其中，这些无关内容在10维空间中标示为其他维度上的不同权重。</p><p>因此，图片全局的表达可以用作第一步的快速筛选，然后再使用局部表达精确检索。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CVPR-2016-Faster-R-CNN-Features-for-Instance-Search&quot;&gt;&lt;a href=&quot;#CVPR-2016-Faster-R-CNN-Features-for-Instance-Search&quot; class=&quot;headerlin
      
    
    </summary>
    
      <category term="Technology" scheme="http://yoursite.com/categories/Technology/"/>
    
    
      <category term="CV" scheme="http://yoursite.com/tags/CV/"/>
    
      <category term="Image Retrieval" scheme="http://yoursite.com/tags/Image-Retrieval/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
  </entry>
  
</feed>
